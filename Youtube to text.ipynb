{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv env\n",
    "!bash env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user --break-system-packages langchain==0.0.292\n",
    "%pip install --user --break-system-packages yt_dlp==2023.7.6\n",
    "%pip install --user --break-system-packages tiktoken==0.5.1\n",
    "%pip install --user --break-system-packages openai==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import OS package\n",
    "import os\n",
    "\n",
    "#Import glob\n",
    "import glob\n",
    "\n",
    "#Import the openai package\n",
    "import openai\n",
    "\n",
    "#Import the yt_dlp as youtube_dl\n",
    "import yt_dlp as youtube_dl\n",
    "\n",
    "#Import DownloadError from yt_dlp\n",
    "from yt_dlp import DownloadError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
      "[debug] yt-dlp version stable@2023.07.06 [b532a3481] (pip) API\n",
      "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': './audios/%(title)s.%(ext)s', 'verbose': True, 'ffmpeg_location': '/bin/ffmpeg', 'compat_opts': set()}\n",
      "[debug] Python 3.11.6 (CPython x86_64 64bit) - Linux-6.5.0-14-generic-x86_64-with-glibc2.38 (OpenSSL 3.0.10 1 Aug 2023, glibc 2.38)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio from https://www.youtube.com/watch?v=tLaLfaIJf-Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] exe versions: ffmpeg 6.0 (setts), ffprobe 6.0\n",
      "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2022.09.24, mutagen-1.47.0, secretstorage-3.3.3, sqlite3-2.6.0, websockets-12.0\n",
      "[debug] Proxy map: {}\n",
      "[debug] Loaded 1855 extractors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tLaLfaIJf-Y\n",
      "[youtube] tLaLfaIJf-Y: Downloading webpage\n",
      "[youtube] tLaLfaIJf-Y: Downloading ios player API JSON\n",
      "[youtube] tLaLfaIJf-Y: Downloading android player API JSON\n",
      "[youtube] tLaLfaIJf-Y: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
      "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] tLaLfaIJf-Y: Downloading 1 format(s): 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Invoking http downloader on \"https://rr2---sn-5jucgv5qc5oq-cagk.googlevideo.com/videoplayback?expire=1705518243&ei=Q9CnZdWtOe_Ez7sPoY26oA8&ip=49.204.77.222&id=o-ADgh5qBMoefN91zs2_KUrt20eU-m1RxIBejebhKQPshk&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=EA&mm=31%2C29&mn=sn-5jucgv5qc5oq-cagk%2Csn-h5576nsy&ms=au%2Crdu&mv=m&mvi=2&pl=19&initcwndbps=1407500&spc=UWF9f0ifFDLDAhEleZuMxqu8FwIyISqo0D5N&vprv=1&svpuc=1&mime=audio%2Fwebm&gir=yes&clen=1068695&dur=81.741&lmt=1583164664523886&mt=1705496218&fvip=5&keepalive=yes&fexp=24007246&c=ANDROID&txp=6211222&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgYdGK6LOAfXTjCpAz7dfQ-aQTwaq_D4CVwZq5Y624foQCIQCtquy3reZUthpB-aft6ACToyv6S3rC5rqNKqGga0Gg5w%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AAO5W4owRgIhAN9FT6U7yhY3LTLwgB900kPPCrjhoWZZsc60Px3UESitAiEA-xkMAz1gDxw3H1_FGbpdfp7WI-iBh1lUen2G2YUKe80%3D\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Destination: ./audios/What's the Difference between Training and Testing Data in Machine Learning？.webm\n",
      "[download] 100% of    1.02MiB in 00:00:00 at 2.12MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] ffmpeg command line: /bin/ffprobe -show_streams 'file:./audios/What'\"'\"'s the Difference between Training and Testing Data in Machine Learning？.webm'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExtractAudio] Destination: ./audios/What's the Difference between Training and Testing Data in Machine Learning？.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] ffmpeg command line: /bin/ffmpeg -y -loglevel repeat+info -i 'file:./audios/What'\"'\"'s the Difference between Training and Testing Data in Machine Learning？.webm' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:./audios/What'\"'\"'s the Difference between Training and Testing Data in Machine Learning？.mp3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting original file ./audios/What's the Difference between Training and Testing Data in Machine Learning？.webm (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "#Add youtube video url\n",
    "youtube_url = \"https://www.youtube.com/watch?v=tLaLfaIJf-Y\"\n",
    "\n",
    "#Directory to save the downloaded video\n",
    "output_dir = \"./audios\"\n",
    "\n",
    "#Config for youtube-dl\n",
    "# Specify the path to ffprobe and ffmpeg executables\n",
    "ffmpeg_path = shutil.which(\"ffmpeg\")\n",
    "\n",
    "ydl_config = {\n",
    "    \"format\": \"bestaudio/best\",\n",
    "    \"postprocessors\": [\n",
    "        {\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\",\n",
    "        }\n",
    "    ],\n",
    "    \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
    "    \"verbose\": True,\n",
    "    \"ffmpeg_location\": ffmpeg_path\n",
    "}\n",
    "\n",
    "#Check if the output directory exists, if not create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#Print a message indicating that the video is being downloaded\n",
    "print(f\"Downloading audio from {youtube_url}\")\n",
    "\n",
    "# Attempt to download the video using specified config\n",
    "# If a DownloadError is raised, attempt to download the video again\n",
    "try:\n",
    "    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "except DownloadError:\n",
    "    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([youtube_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./audios/What's the Difference between Training and Testing Data in Machine Learning？.mp3\n"
     ]
    }
   ],
   "source": [
    "# Find the audio files in the output directory\n",
    "audio_files = glob.glob(os.path.join(output_dir, \"*.mp3\"))\n",
    "\n",
    "# Select the first audio file\n",
    "audio_filename = audio_files[0]\n",
    "\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conveting audio to text...\n"
     ]
    }
   ],
   "source": [
    "# Function parameters\n",
    "audio_file = audio_filename\n",
    "model = \"whisper-1\"\n",
    "\n",
    "# Transcribe the audio file to text using OpenAI API\n",
    "print(\"Conveting audio to text...\")\n",
    "\n",
    "with open(audio_file, \"rb\") as audio:\n",
    "    response = openai.Audio.transcribe(model, audio)\n",
    "\n",
    "# Extract the transcription from the response\n",
    "transcript = (response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, we need to talk about data. So you see here, we have basically a CSV with a bunch of data, right? We have column one and column two. And if you're a bit perceptive, you notice that column three is a simple multiplication operation between column one and column two. Now, what a machine learning algorithm would do essentially is if you would tell it, hey, I have this data, I want to figure out what's the relation between column one and column two that can generate column three, a good machine learning algorithm would basically be able to figure out, oh, it's a multiplication. And you see here, we have a training dataset and a testing dataset. And that's because when we train a machine learning algorithm, when we try to make it figure out relations, we do so on a training dataset. And then we want to test that algorithm to make sure that it's learned something meaningful on some data that it's never seen before. And we call that a testing dataset where we don't actually give the solution.\n"
     ]
    }
   ],
   "source": [
    "output_file = \"./transcripts/output.txt\"\n",
    "\n",
    "# If an output file is specified, write the transcription to the file\n",
    "if output_file is not None:\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    # Write the transcript to the output file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(transcript)\n",
    "\n",
    "# Print the transcription\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TextLoader class from the langchain.document_loaders module\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Create a new instance of the TextLoader class\n",
    "loader = TextLoader(\"./transcripts/output.txt\")\n",
    "\n",
    "# Load the document\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"First, we need to talk about data. So you see here, we have basically a CSV with a bunch of data, right? We have column one and column two. And if you're a bit perceptive, you notice that column three is a simple multiplication operation between column one and column two. Now, what a machine learning algorithm would do essentially is if you would tell it, hey, I have this data, I want to figure out what's the relation between column one and column two that can generate column three, a good machine learning algorithm would basically be able to figure out, oh, it's a multiplication. And you see here, we have a training dataset and a testing dataset. And that's because when we train a machine learning algorithm, when we try to make it figure out relations, we do so on a training dataset. And then we want to test that algorithm to make sure that it's learned something meaningful on some data that it's never seen before. And we call that a testing dataset where we don't actually give the solution.\", metadata={'source': './transcripts/output.txt'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tiktoken package\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RetrievalQA class from the langchain.chains module\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Import the ChatOpenAI class from the langchain.chat_models module\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Import the DocArrayInMemorySearch class from the langchain.vectorstores module\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# Import the OpenAIEmbedding class from the langchain.embeddings module\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DocArrayInMemorySearch instance from the specified document\n",
    "db = DocArrayInMemorySearch.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DocArrayInMemorySearch instance to a retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Create a new ChatOpenAI instance with the temperature of 0.0\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  a new RetrievalQA instance with the specified parameters\n",
    "qa_stuff = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, but I don't have any information about the iPhone 15.\n"
     ]
    }
   ],
   "source": [
    "# Select the query to be used for the QA system\n",
    "query = \"Who is best suited to take this course?\"\n",
    "\n",
    "# Run the query through the RetrievalQA instance and store the response\n",
    "response = qa_stuff.run(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(audio_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
